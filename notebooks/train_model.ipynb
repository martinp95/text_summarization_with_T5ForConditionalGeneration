{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training T5 Model for Text Summarization\n",
    "\n",
    "This notebook demonstrates how to fine-tune a T5 model for text summarization using PyTorch Lightning. The workflow includes loading the dataset, defining the model, training, and saving the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and set up the environment\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to the system path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the DataLoader and Summarizer classes\n",
    "from training import SummarizationDataLoader, Summarizer\n",
    "\n",
    "# Import PyTorch and PyTorch Lightning libraries\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning import Trainer\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Callbacks\n",
    "\n",
    "Two callbacks are defined:\n",
    "- **`ModelCheckpoint`**: Saves the best model based on validation loss.\n",
    "- **`EarlyStopping`**: Halts training if validation loss does not improve for several epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='../checkpoints/',  # Path to save the models\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize DataLoader and Model\n",
    "\n",
    "We set up the `SummarizationDataLoader` for data processing and instantiate the T5 model using the `Summarizer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DataLoader with batch size 8\n",
    "data_module = SummarizationDataLoader(batch_size=8)\n",
    "\n",
    "# Initialize the Summarizer model\n",
    "model = Summarizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "The `Trainer` is configured with defined callbacks and is used to train the model for up to 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Trainer with the callbacks\n",
    "trainer = Trainer(\n",
    "    max_epochs=10,\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "    devices=1 if torch.cuda.is_available() else 1,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Best Model\n",
    "\n",
    "After training, the best model checkpoint is loaded for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model checkpoint\n",
    "best_model_path = os.path.join(\n",
    "    checkpoint_callback.dirpath,\n",
    "    checkpoint_callback.filename + '.ckpt'\n",
    ")\n",
    "\n",
    "# Check if the best model path is not empty\n",
    "if best_model_path:\n",
    "    # Load the model from the checkpoint\n",
    "    model = Summarizer.load_from_checkpoint(best_model_path)\n",
    "    print(f\"The best model has been loaded from : {best_model_path}\")\n",
    "else:\n",
    "    print(\"No best model checkpoint found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "\n",
    "The model is set to evaluation mode and tested using the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "trainer.test(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Save the Model and Tokenizer\n",
    "\n",
    "The fine-tuned model and tokenizer are saved for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and tokenizer\n",
    "model.model.save_pretrained(\"../fine_tuned/fine_tuned_t5\")\n",
    "model.tokenizer.save_pretrained(\"../fine_tuned/fine_tuned_t5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with the Fine-Tuned Model\n",
    "\n",
    "The saved model and tokenizer are loaded to perform text summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model and tokenizer for inference\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"../fine_tuned/fine_tuned_t5\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"../fine_tuned/fine_tuned_t5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for summarization\n",
    "def summary_text(text: str) -> str:\n",
    "    inputs = tokenizer.encode(\n",
    "        \"summarize: \" + text,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=1024,\n",
    "        truncation=True\n",
    "    )\n",
    "    summary_ids = model.generate(\n",
    "        inputs,\n",
    "        max_length=128,\n",
    "        min_length=40,\n",
    "        length_penalty=2.0,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input text for summarization\n",
    "input_text = \"\"\"SECTION 1. LIABILITY OF BUSINESS ENTITIES PROVIDING USE OF FACILITIES TO NONPROFIT ORGANIZATIONS.\n",
    "(a) Definitions.--In this section:\n",
    "    (1) Business entity.--The term \"business entity\" means a firm, corporation, association, partnership, consortium, joint venture, or other form of enterprise.\n",
    "    (2) Facility.--The term \"facility\" means any real property, including any building, improvement, or appurtenance.\n",
    "    (3) Gross negligence.--The term \"gross negligence\" means voluntary and conscious conduct by a person with knowledge (at the time of the conduct) that the conduct is likely to be harmful to the health or well-being of another person.\n",
    "    (4) Intentional misconduct.--The term \"intentional misconduct\" means conduct by a person with knowledge (at the time of the conduct) that the conduct is harmful to the health or well-being of another person.\n",
    "    (5) Nonprofit organization.--The term \"nonprofit organization\" means:\n",
    "        (A) any organization described in section 501(c)(3) of the Internal Revenue Code of 1986 and exempt from tax under section 501(a) of such Code; or\n",
    "        (B) any not-for-profit organization organized and conducted for public benefit and operated primarily for charitable, civic, educational, religious, welfare, or health purposes.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Summary:\", summary_text(input_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_summarization_with_T5ForConditionalGeneration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
